{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr4ubZo-ErQy",
        "outputId": "48b491b6-b688-495f-d340-8bbce3fd118e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-ranking in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-ranking) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-ranking) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-ranking) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-serving-api<3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-ranking) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.44.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.10.0.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.14.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (13.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.24.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (57.4.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<3,>=2.8.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow-ranking) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-ranking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_ranking as tfr\n",
        "\n",
        "training_samples_file_path = \"./trainingSamples.csv\"\n",
        "test_samples_file_path = \"./testSamples.csv\"\n",
        "\n",
        "# load sample as tf dataset\n",
        "def get_dataset(file_path):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_path,\n",
        "        batch_size=12,\n",
        "        label_name='label',\n",
        "        na_value=\"0\",\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# split as test dataset and training dataset\n",
        "train_dataset = get_dataset(training_samples_file_path)\n",
        "test_dataset = get_dataset(test_samples_file_path)\n",
        "\n",
        "\n",
        "genre_vocab  = ['Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
        "              'Film-Noir',\n",
        "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "GENRE_FEATURES = {\n",
        "    'userGenre1': genre_vocab,\n",
        "    'userGenre2': genre_vocab,\n",
        "    'userGenre3': genre_vocab,\n",
        "    'userGenre4': genre_vocab,\n",
        "    'userGenre5': genre_vocab,\n",
        "    'movieGenre1': genre_vocab,\n",
        "    'movieGenre2': genre_vocab,\n",
        "    'movieGenre3': genre_vocab\n",
        "}\n",
        "\n",
        "# all categorical features\n",
        "categorical_columns = []\n",
        "for feature, vocab in GENRE_FEATURES.items():\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
        "    categorical_columns.append(emb_col)\n",
        "# movie id embedding feature\n",
        "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1683)\n",
        "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
        "categorical_columns.append(movie_emb_col)\n",
        "\n",
        "# user id embedding feature\n",
        "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=944)\n",
        "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
        "categorical_columns.append(user_emb_col)\n",
        "\n",
        "# all numerical features\n",
        "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
        "                     tf.feature_column.numeric_column('movieRatingCount'),\n",
        "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
        "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
        "                     tf.feature_column.numeric_column('userRatingCount'),\n",
        "                     tf.feature_column.numeric_column('userAvgRating'),\n",
        "                     tf.feature_column.numeric_column('userRatingStddev')]\n",
        "\n",
        "# embedding + MLP model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "# compile the model, set loss function, optimizer and evaluation metrics\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy',tf.keras.metrics.Precision(top_k=5),tf.keras.metrics.Precision(top_k=10),tfr.keras.metrics.NDCGMetric(),tfr.keras.metrics.NDCGMetric(topn=5),tfr.keras.metrics.NDCGMetric(topn = 10),tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_dataset,epochs=5)\n",
        "\n",
        "# evaluate the model\n",
        "test_loss,test_accuracy,test_accuracy5,test_accuracy10, NDCG,NDCG5,NDCG10, RMSE = model.evaluate(test_dataset)\n",
        "print('\\n\\nTest Loss {},Test Accuracy {},Test Accuracy5 {},Test Accuracy10 {}, NDCG {},NDCG5 {},NDCG10 {}, RMSE {}, '.format(test_loss,test_accuracy,test_accuracy,test_accuracy5,test_accuracy10, NDCG,NDCG5,NDCG10, RMSE))\n",
        "                                                                              \n",
        "\n",
        "# print some predict results\n",
        "predictions = model.predict(test_dataset)\n",
        "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
        "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
        "          \" | Actual rating label: \",\n",
        "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
      ],
      "metadata": {
        "id": "MHSV9fmtE4lx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "b3b4cf26-5caa-4462-e8af-4d2dac2af351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('movieId', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=int32>), ('userId', <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=int32>), ('rating', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=int32>), ('timestamp', <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=int32>), ('releaseYear', <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=int32>), ('movieGenre1', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('movieGenre2', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>), ('movieGenre3', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=string>), ('movieRatingCount', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>), ('movieAvgRating', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=float32>), ('movieRatingStddev', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>), ('userRatedMovie1', <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=int32>), ('userRatedMovie2', <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=int32>), ('userRatedMovie3', <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=int32>), ('userRatedMovie4', <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int32>), ('userRatedMovie5', <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int32>), ('userRatingCount', <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int32>), ('userAvgReleaseYear', <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=int32>), ('userReleaseYearStddev', <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>), ('userAvgRating', <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>), ('userRatingStddev', <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=float32>), ('userGenre1', <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=string>), ('userGenre2', <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=string>), ('userGenre3', <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=string>), ('userGenre4', <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=string>), ('userGenre5', <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-24baf487f70c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 864, in train_step\n        return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 957, in compute_metrics\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 459, in update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 178, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/metrics.py\", line 1414, in update_state  **\n        sample_weight=sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 622, in update_confusion_matrix_variables\n        y_pred = _filter_top_k(y_pred, top_k)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\", line 745, in _filter_top_k\n        _, top_k_idx = tf.math.top_k(x, k, sorted=False)\n\n    ValueError: input must have last dimension >= k = 5 but is 1 for '{{node TopKV2}} = TopKV2[T=DT_FLOAT, sorted=false](sequential_6/dense_29/Sigmoid, TopKV2/k)' with input shapes: [?,1], [] and with computed input tensors: input[1] = <5>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_ranking as tfr\n",
        "\n",
        "training_samples_file_path = \"./trainingSamples.csv\"\n",
        "test_samples_file_path = \"./testSamples.csv\"\n",
        "\n",
        "\n",
        "# load sample as tf dataset\n",
        "def get_dataset(file_path):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_path,\n",
        "        batch_size=12,\n",
        "        label_name='label',\n",
        "        na_value=\"0\",\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# split as test dataset and training dataset\n",
        "train_dataset = get_dataset(training_samples_file_path)\n",
        "test_dataset = get_dataset(test_samples_file_path)\n",
        "\n",
        "# genre features vocabulary\n",
        "genre_vocab = ['Film-Noir', 'Action', 'Adventure', 'Horror', 'Romance', 'War', 'Comedy', 'Western', 'Documentary',\n",
        "               'Sci-Fi', 'Drama', 'Thriller',\n",
        "               'Crime', 'Fantasy', 'Animation', 'IMAX', 'Mystery', 'Children', 'Musical']\n",
        "\n",
        "GENRE_FEATURES = {\n",
        "    'userGenre1': genre_vocab,\n",
        "    'userGenre2': genre_vocab,\n",
        "    'userGenre3': genre_vocab,\n",
        "    'userGenre4': genre_vocab,\n",
        "    'userGenre5': genre_vocab,\n",
        "    'movieGenre1': genre_vocab,\n",
        "    'movieGenre2': genre_vocab,\n",
        "    'movieGenre3': genre_vocab\n",
        "}\n",
        "\n",
        "# all categorical features\n",
        "categorical_columns = []\n",
        "for feature, vocab in GENRE_FEATURES.items():\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "    emb_col = tf.feature_column.embedding_column(cat_col, 10)\n",
        "    categorical_columns.append(emb_col)\n",
        "# movie id embedding feature\n",
        "movie_col = tf.feature_column.categorical_column_with_identity(key='movieId', num_buckets=1683)\n",
        "movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)\n",
        "categorical_columns.append(movie_emb_col)\n",
        "\n",
        "# user id embedding feature\n",
        "user_col = tf.feature_column.categorical_column_with_identity(key='userId', num_buckets=944)\n",
        "user_emb_col = tf.feature_column.embedding_column(user_col, 10)\n",
        "categorical_columns.append(user_emb_col)\n",
        "\n",
        "# all numerical features\n",
        "numerical_columns = [tf.feature_column.numeric_column('releaseYear'),\n",
        "                     tf.feature_column.numeric_column('movieRatingCount'),\n",
        "                     tf.feature_column.numeric_column('movieAvgRating'),\n",
        "                     tf.feature_column.numeric_column('movieRatingStddev'),\n",
        "                     tf.feature_column.numeric_column('userRatingCount'),\n",
        "                     tf.feature_column.numeric_column('userAvgRating'),\n",
        "                     tf.feature_column.numeric_column('userRatingStddev')]\n",
        "\n",
        "# cross feature between current movie and user historical movie\n",
        "rated_movie = tf.feature_column.categorical_column_with_identity(key='userRatedMovie1', num_buckets=1001)\n",
        "crossed_feature = tf.feature_column.indicator_column(tf.feature_column.crossed_column([movie_col, rated_movie], 10000))\n",
        "\n",
        "# define input for keras model\n",
        "inputs = {\n",
        "    'movieAvgRating': tf.keras.layers.Input(name='movieAvgRating', shape=(), dtype='float32'),\n",
        "    'movieRatingStddev': tf.keras.layers.Input(name='movieRatingStddev', shape=(), dtype='float32'),\n",
        "    'movieRatingCount': tf.keras.layers.Input(name='movieRatingCount', shape=(), dtype='int32'),\n",
        "    'userAvgRating': tf.keras.layers.Input(name='userAvgRating', shape=(), dtype='float32'),\n",
        "    'userRatingStddev': tf.keras.layers.Input(name='userRatingStddev', shape=(), dtype='float32'),\n",
        "    'userRatingCount': tf.keras.layers.Input(name='userRatingCount', shape=(), dtype='int32'),\n",
        "    'releaseYear': tf.keras.layers.Input(name='releaseYear', shape=(), dtype='int32'),\n",
        "\n",
        "    'movieId': tf.keras.layers.Input(name='movieId', shape=(), dtype='int32'),\n",
        "    'userId': tf.keras.layers.Input(name='userId', shape=(), dtype='int32'),\n",
        "    'userRatedMovie1': tf.keras.layers.Input(name='userRatedMovie1', shape=(), dtype='int32'),\n",
        "\n",
        "    'userGenre1': tf.keras.layers.Input(name='userGenre1', shape=(), dtype='string'),\n",
        "    'userGenre2': tf.keras.layers.Input(name='userGenre2', shape=(), dtype='string'),\n",
        "    'userGenre3': tf.keras.layers.Input(name='userGenre3', shape=(), dtype='string'),\n",
        "    'userGenre4': tf.keras.layers.Input(name='userGenre4', shape=(), dtype='string'),\n",
        "    'userGenre5': tf.keras.layers.Input(name='userGenre5', shape=(), dtype='string'),\n",
        "    'movieGenre1': tf.keras.layers.Input(name='movieGenre1', shape=(), dtype='string'),\n",
        "    'movieGenre2': tf.keras.layers.Input(name='movieGenre2', shape=(), dtype='string'),\n",
        "    'movieGenre3': tf.keras.layers.Input(name='movieGenre3', shape=(), dtype='string'),\n",
        "}\n",
        "\n",
        "# wide and deep model architecture\n",
        "# deep part for all input features\n",
        "deep = tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)(inputs)\n",
        "deep = tf.keras.layers.Dense(128, activation='relu')(deep)\n",
        "deep = tf.keras.layers.Dense(128, activation='relu')(deep)\n",
        "# wide part for cross feature\n",
        "wide = tf.keras.layers.DenseFeatures(crossed_feature)(inputs)\n",
        "both = tf.keras.layers.concatenate([deep, wide])\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(both)\n",
        "model = tf.keras.Model(inputs, output_layer)\n",
        "\n",
        "# compile the model, set loss function, optimizer and evaluation metrics\n",
        "# compile the model, set loss function, optimizer and evaluation metrics\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy', tfr.keras.metrics.NDCGMetric(),tfr.keras.metrics.NDCGMetric(topn=5),tfr.keras.metrics.NDCGMetric(topn=10),tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_dataset,epochs=5)\n",
        "\n",
        "# evaluate the model\n",
        "test_loss,test_accuracy, NDCG,NDCG5,NDCG10, RMSE = model.evaluate(test_dataset)\n",
        "print('\\n\\nTest Loss {},Test Accuracy {}, NDCG {},NDCG5 {},NDCG10 {}, RMSE {}, '.format(test_loss,test_accuracy,NDCG,NDCG5,NDCG10, RMSE)) \n",
        "\n",
        "# print some predict results\n",
        "predictions = model.predict(test_dataset)\n",
        "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
        "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
        "          \" | Actual rating label: \",\n",
        "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khcEsWg1gE06",
        "outputId": "d62bfb06-3fd6-4dd7-931e-e4f74fc4772c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['rating', 'timestamp', 'userRatedMovie2', 'userRatedMovie3', 'userRatedMovie4', 'userRatedMovie5', 'userAvgReleaseYear', 'userReleaseYearStddev'] which did not match any model input. They will be ignored by the model.\n",
            "  inputs = self._flatten_to_reference_inputs(inputs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6540/6540 [==============================] - 53s 7ms/step - loss: 0.6627 - accuracy: 0.6268 - ndcg_metric_9: 0.5516 - ndcg_metric_10: 0.5516 - ndcg_metric_11: 0.5516 - root_mean_squared_error: 0.4806\n",
            "Epoch 2/5\n",
            "6540/6540 [==============================] - 47s 7ms/step - loss: 0.5719 - accuracy: 0.7039 - ndcg_metric_9: 0.5516 - ndcg_metric_10: 0.5516 - ndcg_metric_11: 0.5516 - root_mean_squared_error: 0.4410\n",
            "Epoch 3/5\n",
            "6540/6540 [==============================] - 47s 7ms/step - loss: 0.5475 - accuracy: 0.7257 - ndcg_metric_9: 0.5516 - ndcg_metric_10: 0.5516 - ndcg_metric_11: 0.5516 - root_mean_squared_error: 0.4292\n",
            "Epoch 4/5\n",
            "6540/6540 [==============================] - 48s 7ms/step - loss: 0.5353 - accuracy: 0.7338 - ndcg_metric_9: 0.5516 - ndcg_metric_10: 0.5516 - ndcg_metric_11: 0.5516 - root_mean_squared_error: 0.4234\n",
            "Epoch 5/5\n",
            "6540/6540 [==============================] - 48s 7ms/step - loss: 0.5264 - accuracy: 0.7396 - ndcg_metric_9: 0.5516 - ndcg_metric_10: 0.5516 - ndcg_metric_11: 0.5516 - root_mean_squared_error: 0.4191\n",
            "1637/1637 [==============================] - 10s 5ms/step - loss: 0.5707 - accuracy: 0.7065 - ndcg_metric_9: 0.5570 - ndcg_metric_10: 0.5570 - ndcg_metric_11: 0.5570 - root_mean_squared_error: 0.4395\n",
            "\n",
            "\n",
            "Test Loss 0.5706813335418701,Test Accuracy 0.706502377986908, NDCG 0.557003915309906,NDCG5 0.557003915309906,NDCG10 0.557003915309906, RMSE 0.4395201504230499, \n",
            "Predicted good rating: 52.04%  | Actual rating label:  Good Rating\n",
            "Predicted good rating: 54.24%  | Actual rating label:  Good Rating\n",
            "Predicted good rating: 54.75%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 4.54%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 33.31%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 24.18%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 76.01%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 23.52%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 44.80%  | Actual rating label:  Good Rating\n",
            "Predicted good rating: 75.06%  | Actual rating label:  Bad Rating\n",
            "Predicted good rating: 54.32%  | Actual rating label:  Good Rating\n",
            "Predicted good rating: 29.12%  | Actual rating label:  Good Rating\n"
          ]
        }
      ]
    }
  ]
}